{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e5094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tab_transformer_pytorch import TabTransformer \n",
    "from preprocessing import get_features_and_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493927ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m x_categ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m)     \u001b[38;5;66;03m# category values, from 0 - max number of categories, in the order as passed into the constructor above\u001b[39;00m\n\u001b[0;32m     18\u001b[0m x_cont \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m16\u001b[39m)               \u001b[38;5;66;03m# assume continuous values are already normalized individually\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_categ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_cont\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (1, 1)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred)\n",
      "File \u001b[1;32mc:\\Users\\Marcus\\miniconda3\\envs\\MLDA\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Marcus\\miniconda3\\envs\\MLDA\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Marcus\\miniconda3\\envs\\MLDA\\lib\\site-packages\\tab_transformer_pytorch\\tab_transformer_pytorch.py:235\u001b[0m, in \u001b[0;36mTabTransformer.forward\u001b[1;34m(self, x_categ, x_cont, return_attn)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_categ, x_cont, return_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    233\u001b[0m     xs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mx_categ\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_categories, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myou must pass in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_categories\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m values for your categories input\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_unique_categories \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    238\u001b[0m         x_categ \u001b[38;5;241m=\u001b[39m x_categ \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories_offset\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "cont_mean_std = torch.randn(16, 2)\n",
    "\n",
    "model = TabTransformer(\n",
    "    categories = (9,16 ),      # tuple containing the number of unique values within each category\n",
    "    num_continuous = 16,                # number of continuous values\n",
    "    dim = 32,                           # dimension, paper set at 32\n",
    "    dim_out = 1,                        # binary prediction, but could be anything\n",
    "    depth = 6,                          # depth, paper recommended 6\n",
    "    heads = 8,                          # heads, paper recommends 8\n",
    "    attn_dropout = 0.1,                 # post-attention dropout\n",
    "    ff_dropout = 0.1,                   # feed forward dropout\n",
    "    mlp_hidden_mults = (4, 2),          # relative multiples of each hidden dimension of the last mlp to logits\n",
    "    mlp_act = nn.ReLU(),                # activation for final mlp, defaults to relu, but could be anything else (selu etc)\n",
    "    continuous_mean_std = cont_mean_std # (optional) - normalize the continuous values before layer norm\n",
    ")\n",
    "\n",
    "x_categ = (9, 12)     # category values, from 0 - max number of categories, in the order as passed into the constructor above\n",
    "x_cont = (1, 16)               # assume continuous values are already normalized individually\n",
    "\n",
    "pred = model(x_categ, x_cont) # (1, 1)\n",
    "print(pred)\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "244e528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tab_transformer_pytorch import FTTransformer\n",
    "\n",
    "model = FTTransformer(\n",
    "    categories = (1,1),      # tuple containing the number of unique values within each category\n",
    "    num_continuous = 10,                # number of continuous values\n",
    "    dim = 32,                           # dimension, paper set at 32\n",
    "    dim_out = 1,                        # binary prediction, but could be anything\n",
    "    depth = 6,                          # depth, paper recommended 6\n",
    "    heads = 8,                          # heads, paper recommends 8\n",
    "    attn_dropout = 0.1,                 # post-attention dropout\n",
    "    ff_dropout = 0.1                    # feed forward dropout\n",
    ")\n",
    "\n",
    "x_categ = torch.randint(0, 1, (1, 2))     # category values, from 0 - max number of categories, in the order as passed into the constructor above\n",
    "x_numer = torch.randn(1, 10)              # numerical value\n",
    "\n",
    "pred = model(x_categ, x_numer) # (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76250c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 0.6152, Accuracy: 0.7224\n",
      "Epoch [2/2], Loss: 0.4350, Accuracy: 0.8031\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Generate fake data\n",
    "def generate_data(num_samples):\n",
    "    x_categ = torch.randint(0, 10, (num_samples, 5))\n",
    "    \n",
    "    x_cont = torch.randn(num_samples, 15)\n",
    "    \n",
    "    y = torch.zeros(num_samples)\n",
    "    for i in range(num_samples):\n",
    "        if x_categ[i, 0] > 5 and x_cont[i, 0] > 0:\n",
    "            y[i] = 2  \n",
    "        elif x_categ[i, 1] < 3 or x_cont[i, 1] < -1:\n",
    "            y[i] = 1 \n",
    "        else:\n",
    "            y[i] = 0  \n",
    "    \n",
    "    return x_categ, x_cont, y.long()\n",
    "\n",
    "num_samples = 10000\n",
    "x_categ, x_cont, y = generate_data(num_samples)\n",
    "\n",
    "cont_mean = x_cont.mean(dim=0)\n",
    "cont_std = x_cont.std(dim=0)\n",
    "x_cont = (x_cont - cont_mean) / cont_std \n",
    "cont_mean_std = torch.stack([cont_mean, cont_std], dim=1)\n",
    "\n",
    "# Model\n",
    "model = TabTransformer(\n",
    "    categories = (10, 10, 10, 10, 10), \n",
    "    num_continuous = 15,                \n",
    "    dim = 64,                            \n",
    "    dim_out = 3,                        \n",
    "    depth = 6,                           \n",
    "    heads = 8,                          \n",
    "    attn_dropout = 0.1,                  \n",
    "    ff_dropout = 0.1,                    \n",
    "    mlp_hidden_mults = (4, 2),           \n",
    "    mlp_act = nn.ReLU(),                 \n",
    "    continuous_mean_std = cont_mean_std  \n",
    ")\n",
    "\n",
    "dataset = TensorDataset(x_categ, x_cont, y)\n",
    "train_size = int(0.8 * len(dataset))  \n",
    "test_size = len(dataset) - train_size \n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)  \n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)  \n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) \n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "# Train\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    total_loss = 0\n",
    "    all_preds = []  \n",
    "    all_labels = []  \n",
    "\n",
    "    for batch_categ, batch_cont, batch_y in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()  \n",
    "        \n",
    "        outputs = model(batch_categ, batch_cont)\n",
    "        loss = criterion(outputs, batch_y)  \n",
    "        \n",
    "        loss.backward() \n",
    "        optimizer.step()  \n",
    "        \n",
    "        total_loss += loss.item()  \n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1) \n",
    "        all_preds.extend(predicted.numpy())  \n",
    "        all_labels.extend(batch_y.numpy())  \n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8148a3ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "FTTransformer.__init__() got an unexpected keyword argument 'random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFTTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mFTTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Tree\u001b[39m\u001b[38;5;124m\"\u001b[39m: DecisionTreeRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m: RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBoost\u001b[39m\u001b[38;5;124m\"\u001b[39m: XGBRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),\n\u001b[0;32m      6\u001b[0m }\n",
      "\u001b[1;31mTypeError\u001b[0m: FTTransformer.__init__() got an unexpected keyword argument 'random_state'"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"FTTransformer\": FTTransformer(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963edeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train_data.csv\")\n",
    "dev_df = pd.read_csv(\"data/development_data.csv\")\n",
    "\n",
    "x_train, y_train = get_features_and_target(train_df)\n",
    "x_dev, y_dev = get_features_and_target(dev_df)\n",
    "\n",
    "target_column = \"PullTest (N)\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3222b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_features_and_target(train_df)\n",
    "num_unique_materials = X[\"Material\"].nunique()\n",
    "num_cont_features = X.shape[1] - 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6631d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X['Material'] = le.fit_transform(X['Material'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bb05559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcus\\AppData\\Local\\Temp\\ipykernel_2964\\1061618069.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  x_numer = torch.tensor([sample.drop(\"Material\").to_numpy()], dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "sample = X.iloc[0]\n",
    "\n",
    "# Get the encoded material category value\n",
    "material_idx = sample[\"Material\"]\n",
    "x_categ = torch.tensor([[material_idx]], dtype=torch.long)\n",
    "\n",
    "# Drop the \"Material\" column to get the continuous features\n",
    "x_numer = torch.tensor([sample.drop(\"Material\").to_numpy()], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2ae24c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4484]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "\n",
    "\n",
    "\n",
    "model = FTTransformer(\n",
    "    categories = (num_unique_materials,),  # Only one categorical feature\n",
    "    num_continuous = num_cont_features,    # Number of continuous columns after preprocessing\n",
    "    dim = 64,\n",
    "    dim_out = 1,\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    attn_dropout = 0.9,\n",
    "    ff_dropout = 0.9\n",
    ")\n",
    "\n",
    "x_categ = torch.tensor([[material_idx]], dtype=torch.long)\n",
    "x_numer = torch.tensor([sample.drop(\"Material\").to_numpy()], dtype=torch.float)\n",
    "\n",
    "\n",
    "\n",
    "pred = model(x_categ, x_numer) # (1, 1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcf50726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Split\n",
    "X, y = get_features_and_target(train_df)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Encode Material\n",
    "le = LabelEncoder()\n",
    "X_train[\"Material\"] = le.fit_transform(X_train[\"Material\"])\n",
    "X_val[\"Material\"] = le.transform(X_val[\"Material\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea41fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class WeldingDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.reset_index(drop=True)\n",
    "        self.y = y.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.X.iloc[idx]\n",
    "        x_categ = torch.tensor([row[\"Material\"]], dtype=torch.long)\n",
    "        x_numer = torch.tensor(row.drop(\"Material\").to_numpy(), dtype=torch.float)\n",
    "        target = torch.tensor(self.y[idx], dtype=torch.float)\n",
    "        return x_categ, x_numer, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1273e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = WeldingDataset(X_train, y_train)\n",
    "val_ds = WeldingDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bbe6b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 321275.9509 | Val Loss: 266071.6172\n",
      "Epoch 2 | Train Loss: 321435.9799 | Val Loss: 266071.6172\n",
      "Epoch 3 | Train Loss: 322136.1741 | Val Loss: 266071.6172\n",
      "Epoch 4 | Train Loss: 322029.5714 | Val Loss: 266071.6172\n",
      "Epoch 5 | Train Loss: 321715.2768 | Val Loss: 266071.6172\n",
      "Epoch 6 | Train Loss: 321826.6987 | Val Loss: 266071.6172\n",
      "Epoch 7 | Train Loss: 321259.3170 | Val Loss: 266071.6172\n",
      "Epoch 8 | Train Loss: 321735.8549 | Val Loss: 266071.6172\n",
      "Epoch 9 | Train Loss: 321409.9375 | Val Loss: 266071.6172\n",
      "Epoch 10 | Train Loss: 321833.7589 | Val Loss: 266071.6172\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = FTTransformer(\n",
    "    categories=(len(le.classes_),),\n",
    "    num_continuous=X_train.shape[1] - 1,\n",
    "    dim=128,\n",
    "    dim_out=1,\n",
    "    depth=6,\n",
    "    heads=8,\n",
    "    attn_dropout=0.9,\n",
    "    ff_dropout=0.9\n",
    ")\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for x_categ, x_numer, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_categ, x_numer).squeeze()\n",
    "        loss = criterion(preds, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # ðŸ” Validation\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x_categ, x_numer, target in val_loader:\n",
    "            preds = model(x_categ, x_numer).squeeze()\n",
    "            loss = criterion(preds, target)\n",
    "            epoch_val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "182d913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from preprocessing import get_features_and_target\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"data/train_data.csv\")\n",
    "\n",
    "# Preprocess\n",
    "X, y = get_features_and_target(df)\n",
    "\n",
    "# Encode categorical column\n",
    "le = LabelEncoder()\n",
    "X[\"Material\"] = le.fit_transform(X[\"Material\"])\n",
    "\n",
    "# Prepare tensors\n",
    "x_categ = torch.tensor(X[\"Material\"].values, dtype=torch.long).unsqueeze(1)  # shape (N, 1)\n",
    "x_cont = torch.tensor(X.drop(\"Material\", axis=1).values, dtype=torch.float)   # shape (N, num_cont_features)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f7a2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tab_transformer_pytorch import FTTransformer\n",
    "\n",
    "model = FTTransformer(\n",
    "    categories=(len(le.classes_),),  # number of unique materials\n",
    "    num_continuous=x_cont.shape[1],  # number of continuous features\n",
    "    dim=64,\n",
    "    dim_out=1,\n",
    "    depth=6,\n",
    "    heads=8,\n",
    "    attn_dropout=0.1,\n",
    "    ff_dropout=0.1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58e09781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([274, 1])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model(x_categ, x_cont)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c77a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale target\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_val_scaled = scaler_y.transform(y_val.values.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09d9a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale continuous features\n",
    "cont_cols = X_train.columns.drop(\"Material\")\n",
    "scaler_X = StandardScaler()\n",
    "X_train[cont_cols] = scaler_X.fit_transform(X_train[cont_cols])\n",
    "X_val[cont_cols] = scaler_X.transform(X_val[cont_cols])\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb874fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaled = pd.Series(y_scaled, index=y.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64e62867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 2975.6613 | Val Loss: 2925.1812\n",
      "Epoch 2 | Train Loss: 2975.0357 | Val Loss: 2925.1700\n",
      "Epoch 3 | Train Loss: 2974.4569 | Val Loss: 2925.1589\n",
      "Epoch 4 | Train Loss: 2974.6929 | Val Loss: 2925.1478\n",
      "Epoch 5 | Train Loss: 2979.2631 | Val Loss: 2925.1366\n",
      "Epoch 6 | Train Loss: 2978.3527 | Val Loss: 2925.1254\n",
      "Epoch 7 | Train Loss: 2976.0774 | Val Loss: 2925.1140\n",
      "Epoch 8 | Train Loss: 2975.7725 | Val Loss: 2925.1029\n",
      "Epoch 9 | Train Loss: 2979.2122 | Val Loss: 2925.0916\n",
      "Epoch 10 | Train Loss: 2978.7967 | Val Loss: 2925.0803\n",
      "Epoch 11 | Train Loss: 2978.6965 | Val Loss: 2925.0691\n",
      "Epoch 12 | Train Loss: 2974.4765 | Val Loss: 2925.0576\n",
      "Epoch 13 | Train Loss: 2977.8728 | Val Loss: 2925.0455\n",
      "Epoch 14 | Train Loss: 2975.5064 | Val Loss: 2925.0337\n",
      "Epoch 15 | Train Loss: 2977.4594 | Val Loss: 2925.0215\n",
      "Epoch 16 | Train Loss: 2977.2197 | Val Loss: 2925.0093\n",
      "Epoch 17 | Train Loss: 2976.8612 | Val Loss: 2924.9972\n",
      "Epoch 18 | Train Loss: 2976.6198 | Val Loss: 2924.9849\n",
      "Epoch 19 | Train Loss: 2976.6868 | Val Loss: 2924.9727\n",
      "Epoch 20 | Train Loss: 2976.8002 | Val Loss: 2924.9606\n",
      "Epoch 21 | Train Loss: 2979.0987 | Val Loss: 2924.9481\n",
      "Epoch 22 | Train Loss: 2975.1048 | Val Loss: 2924.9366\n",
      "Epoch 23 | Train Loss: 2976.1375 | Val Loss: 2924.9250\n",
      "Epoch 24 | Train Loss: 2979.6670 | Val Loss: 2924.9136\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(preds, target)\n\u001b[0;32m     68\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 69\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     epoch_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     71\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m epoch_train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "File \u001b[1;32mc:\\Users\\Marcus\\miniconda3\\envs\\MLDA\\lib\\site-packages\\torch\\optim\\optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m             )\n\u001b[1;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marcus\\miniconda3\\envs\\MLDA\\lib\\site-packages\\torch\\optim\\optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\Marcus\\miniconda3\\envs\\MLDA\\lib\\site-packages\\torch\\optim\\adam.py:246\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    234\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    236\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    237\u001b[0m         group,\n\u001b[0;32m    238\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    243\u001b[0m         state_steps,\n\u001b[0;32m    244\u001b[0m     )\n\u001b[1;32m--> 246\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoupled_weight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Marcus\\miniconda3\\envs\\MLDA\\lib\\site-packages\\torch\\optim\\optimizer.py:147\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Marcus\\miniconda3\\envs\\MLDA\\lib\\site-packages\\torch\\optim\\adam.py:933\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    931\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 933\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Marcus\\miniconda3\\envs\\MLDA\\lib\\site-packages\\torch\\optim\\adam.py:525\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[0;32m    523\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 525\u001b[0m         denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    529\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import RMSELoss\n",
    "\n",
    "# Define RMSELoss directly in the notebook to avoid import issues\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        return torch.sqrt(torch.mean((yhat - y) ** 2))\n",
    "\n",
    "# Custom Dataset for Tabular Data\n",
    "class WeldingDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.reset_index(drop=True)\n",
    "        self.y = y.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.X.iloc[idx]\n",
    "        x_categ = torch.tensor([row[\"Material\"]], dtype=torch.long)\n",
    "        x_numer = torch.tensor(row.drop(\"Material\").to_numpy(), dtype=torch.float)\n",
    "        target = torch.tensor(self.y.iloc[idx], dtype=torch.float)\n",
    "        return x_categ, x_numer, target\n",
    "\n",
    "# Split into train/val\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Datasets and DataLoaders\n",
    "train_ds = WeldingDataset(X_train, y_train)\n",
    "val_ds = WeldingDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32)\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "model = FTTransformer(\n",
    "    categories=(len(le.classes_),),\n",
    "    num_continuous=x_cont.shape[1],\n",
    "    dim=16,\n",
    "    dim_out=1,\n",
    "    depth=4,\n",
    "    heads=4,\n",
    "    attn_dropout=0.3,\n",
    "    ff_dropout=0.3\n",
    ")\n",
    "criterion = RMSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "#prev lr = 0.01\n",
    "\n",
    "# Training and Validation Loop\n",
    "num_epochs = 1000\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for x_categ, x_numer, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_categ, x_numer).squeeze()\n",
    "        loss = criterion(preds, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x_categ, x_numer, target in val_loader:\n",
    "            preds = model(x_categ, x_numer).squeeze()\n",
    "            loss = criterion(preds, target)\n",
    "            epoch_val_loss += loss.item()\n",
    "    avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1dfe6174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Train Loss",
         "type": "scatter",
         "y": [
          8848405.07142857,
          8836080.785714285,
          8825231.07142857,
          8795737.42857143,
          8764566.714285715,
          8727679.857142856,
          8688670,
          8651484.07142857,
          8584665.42857143,
          8534214.214285715,
          8468545.142857144,
          8390187.42857143,
          8330730.428571428,
          8244747.785714285,
          8150729.928571428,
          8088536,
          7961788.357142857,
          7855609.5,
          7771419,
          7634558.714285715,
          7492606.642857143,
          7368068.785714285,
          7233734.928571428,
          7111824.571428572,
          6948566.428571428,
          6802778.428571428,
          6655900.785714285,
          6502575.071428572,
          6356014.785714285,
          6173151.5,
          6018712.5,
          5855941.285714285,
          5687733.071428572,
          5531100,
          5360424.142857143,
          5168339,
          5020540.357142857,
          4837409.928571428,
          4667398.785714285,
          4503926.107142857,
          4323799.5,
          4156602.714285714,
          4012625.6071428573,
          3837760.964285714,
          3657420.714285714,
          3503868.6071428573,
          3349097.1071428573,
          3186274.6428571427,
          3028896.0714285714,
          2879524.3214285714,
          2737197.6071428573,
          2607070.8214285714,
          2456502.8928571427,
          2321816.4464285714,
          2194904.0535714286,
          2078894.5,
          1951395.392857143,
          1834670.75,
          1731724.9285714286,
          1624437.0535714286,
          1516107.6964285714,
          1429027.125,
          1325684.5714285714,
          1234807.6964285714,
          1152211.482142857,
          1085491.4910714286,
          1008244.0357142857,
          935946.25,
          880308.8839285715,
          815967.4732142857,
          751928.4464285715,
          700387.28125,
          665562.4910714285,
          609304.96875,
          578434.1339285715,
          530328.7901785715,
          487778.89285714284,
          462370.71875,
          424313.4776785714,
          395916.27678571426,
          379515.12053571426,
          357386.81696428574,
          331813.41741071426,
          310713.15848214284,
          295253.85714285716,
          284771.87723214284,
          268213.828125,
          254062.3482142857,
          245977.41517857142,
          239040.86495535713,
          226651.92745535713,
          222955.6255580357,
          211763.49330357142,
          205951.57254464287,
          199803.1205357143,
          197600.203125,
          192712.0658482143,
          198915.29575892858,
          185857.90234375,
          182684.90011160713
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Validation Loss",
         "type": "scatter",
         "y": [
          8530666.5,
          8512824.5,
          8490935,
          8464586.25,
          8433376.75,
          8397038,
          8355176.25,
          8307552.25,
          8253822.25,
          8194256.75,
          8128483.5,
          8056443.25,
          7978404,
          7893915.5,
          7803333,
          7706896.75,
          7604264,
          7495976.25,
          7382346.75,
          7263097,
          7138570,
          7009245.25,
          6875256.25,
          6736954.5,
          6594151,
          6447450.25,
          6297349.5,
          6144033.25,
          5987753.75,
          5828300.25,
          5667201.75,
          5503884,
          5338685.5,
          5173080.5,
          5006009.75,
          4837791.25,
          4669774,
          4501878.25,
          4334242.5,
          4167577.75,
          4001739.375,
          3837473.375,
          3675334.25,
          3514763,
          3356156.875,
          3200108.875,
          3047657.5,
          2897309.375,
          2750810.25,
          2607544.875,
          2468649.5,
          2333613.125,
          2202014.25,
          2074997.9375,
          1952642.4375,
          1834553.25,
          1720389.375,
          1610526.25,
          1506716.5625,
          1406864.9375,
          1311559.625,
          1221267.3125,
          1135030.6875,
          1053265.90625,
          976501.65625,
          905073.53125,
          837297.8125,
          773930.71875,
          714763.9375,
          659198.8125,
          607948.21875,
          560112.390625,
          516343.828125,
          475353.84375,
          438054.296875,
          403604.59375,
          372207.671875,
          343687.203125,
          317163.234375,
          293926.5546875,
          272397.7421875,
          253388.953125,
          236313.2421875,
          221024.9453125,
          207131.9765625,
          195098.8671875,
          184374.4140625,
          174929.8203125,
          166608.1640625,
          159089.7109375,
          152569.5,
          147184.40625,
          142289.27734375,
          138108.78125,
          134559.96484375,
          131550.13671875,
          128821.953125,
          126592.19921875,
          124680.1640625,
          123096.21484375
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training & Validation Loss Over Epochs"
        },
        "xaxis": {
         "tickmode": "linear",
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=train_losses,\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"Train Loss\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=val_losses,\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"Validation Loss\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Training & Validation Loss Over Epochs\",\n",
    "    xaxis_title=\"Epoch\",\n",
    "    yaxis_title=\"Loss\",\n",
    "    xaxis = dict(tickmode='linear'),  # optional: shows every epoch\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe7db594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "royalblue",
          "width": 2
         },
         "marker": {
          "size": 6
         },
         "mode": "lines+markers",
         "name": "Training Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "y": [
          8848405.07142857,
          8836080.785714285,
          8825231.07142857,
          8795737.42857143,
          8764566.714285715,
          8727679.857142856,
          8688670,
          8651484.07142857,
          8584665.42857143,
          8534214.214285715,
          8468545.142857144,
          8390187.42857143,
          8330730.428571428,
          8244747.785714285,
          8150729.928571428,
          8088536,
          7961788.357142857,
          7855609.5,
          7771419,
          7634558.714285715,
          7492606.642857143,
          7368068.785714285,
          7233734.928571428,
          7111824.571428572,
          6948566.428571428,
          6802778.428571428,
          6655900.785714285,
          6502575.071428572,
          6356014.785714285,
          6173151.5,
          6018712.5,
          5855941.285714285,
          5687733.071428572,
          5531100,
          5360424.142857143,
          5168339,
          5020540.357142857,
          4837409.928571428,
          4667398.785714285,
          4503926.107142857,
          4323799.5,
          4156602.714285714,
          4012625.6071428573,
          3837760.964285714,
          3657420.714285714,
          3503868.6071428573,
          3349097.1071428573,
          3186274.6428571427,
          3028896.0714285714,
          2879524.3214285714,
          2737197.6071428573,
          2607070.8214285714,
          2456502.8928571427,
          2321816.4464285714,
          2194904.0535714286,
          2078894.5,
          1951395.392857143,
          1834670.75,
          1731724.9285714286,
          1624437.0535714286,
          1516107.6964285714,
          1429027.125,
          1325684.5714285714,
          1234807.6964285714,
          1152211.482142857,
          1085491.4910714286,
          1008244.0357142857,
          935946.25,
          880308.8839285715,
          815967.4732142857,
          751928.4464285715,
          700387.28125,
          665562.4910714285,
          609304.96875,
          578434.1339285715,
          530328.7901785715,
          487778.89285714284,
          462370.71875,
          424313.4776785714,
          395916.27678571426,
          379515.12053571426,
          357386.81696428574,
          331813.41741071426,
          310713.15848214284,
          295253.85714285716,
          284771.87723214284,
          268213.828125,
          254062.3482142857,
          245977.41517857142,
          239040.86495535713,
          226651.92745535713,
          222955.6255580357,
          211763.49330357142,
          205951.57254464287,
          199803.1205357143,
          197600.203125,
          192712.0658482143,
          198915.29575892858,
          185857.90234375,
          182684.90011160713
         ]
        },
        {
         "line": {
          "color": "tomato",
          "width": 2
         },
         "marker": {
          "size": 6
         },
         "mode": "lines+markers",
         "name": "Validation Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "y": [
          8530666.5,
          8512824.5,
          8490935,
          8464586.25,
          8433376.75,
          8397038,
          8355176.25,
          8307552.25,
          8253822.25,
          8194256.75,
          8128483.5,
          8056443.25,
          7978404,
          7893915.5,
          7803333,
          7706896.75,
          7604264,
          7495976.25,
          7382346.75,
          7263097,
          7138570,
          7009245.25,
          6875256.25,
          6736954.5,
          6594151,
          6447450.25,
          6297349.5,
          6144033.25,
          5987753.75,
          5828300.25,
          5667201.75,
          5503884,
          5338685.5,
          5173080.5,
          5006009.75,
          4837791.25,
          4669774,
          4501878.25,
          4334242.5,
          4167577.75,
          4001739.375,
          3837473.375,
          3675334.25,
          3514763,
          3356156.875,
          3200108.875,
          3047657.5,
          2897309.375,
          2750810.25,
          2607544.875,
          2468649.5,
          2333613.125,
          2202014.25,
          2074997.9375,
          1952642.4375,
          1834553.25,
          1720389.375,
          1610526.25,
          1506716.5625,
          1406864.9375,
          1311559.625,
          1221267.3125,
          1135030.6875,
          1053265.90625,
          976501.65625,
          905073.53125,
          837297.8125,
          773930.71875,
          714763.9375,
          659198.8125,
          607948.21875,
          560112.390625,
          516343.828125,
          475353.84375,
          438054.296875,
          403604.59375,
          372207.671875,
          343687.203125,
          317163.234375,
          293926.5546875,
          272397.7421875,
          253388.953125,
          236313.2421875,
          221024.9453125,
          207131.9765625,
          195098.8671875,
          184374.4140625,
          174929.8203125,
          166608.1640625,
          159089.7109375,
          152569.5,
          147184.40625,
          142289.27734375,
          138108.78125,
          134559.96484375,
          131550.13671875,
          128821.953125,
          126592.19921875,
          124680.1640625,
          123096.21484375
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "rgba(255,255,255,0)",
         "borderwidth": 0,
         "x": 0.02,
         "y": 0.98
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training & Validation Loss over Epochs"
        },
        "xaxis": {
         "tickmode": "linear",
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Training loss trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=train_losses,\n",
    "    x=list(range(1, len(train_losses)+1)),\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"Training Loss\",\n",
    "    line=dict(color=\"royalblue\", width=2),\n",
    "    marker=dict(size=6)\n",
    "))\n",
    "\n",
    "# Validation loss trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=val_losses,\n",
    "    x=list(range(1, len(val_losses)+1)),\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"Validation Loss\",\n",
    "    line=dict(color=\"tomato\", width=2),\n",
    "    marker=dict(size=6)\n",
    "))\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    title=\"Training & Validation Loss over Epochs\",\n",
    "    xaxis_title=\"Epoch\",\n",
    "    yaxis_title=\"Loss\",\n",
    "    xaxis=dict(tickmode='linear'),\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(x=0.02, y=0.98, bgcolor=\"rgba(255,255,255,0)\", borderwidth=0)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b260a996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "royalblue",
          "width": 2
         },
         "mode": "lines",
         "name": "Training Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000
         ],
         "y": [
          1.159616355385099,
          1.0592988346304213,
          1.0557812580040522,
          1.0351162723132543,
          1.0671392508915492,
          1.0500588864088058,
          1.0717898777553014,
          1.0379191509314947,
          1.0256839650017875,
          1.0221161437886102,
          1.013328424521855,
          1.0044104095016206,
          1.0046174845525198,
          1.0534344805138451,
          1.004483855196408,
          1.0194117213998521,
          1.0310894293444497,
          1.0244262835809164,
          1.0107654929161072,
          1.0065660306385584,
          1.0020288058689661,
          1.0102427005767822,
          1.0236342464174544,
          1.009455761739186,
          0.9880580753087997,
          0.987643654857363,
          1.0358568685395377,
          1.00050060238157,
          1.0036521341119493,
          1.019803530403546,
          0.9581803381443024,
          0.9922051983220237,
          1.0049527840954917,
          1.0315125158854894,
          1.0256859873022353,
          0.9990539678505489,
          0.9964794218540192,
          0.9918533670050758,
          1.0221114669527327,
          1.0138330268008369,
          1.0142547360488348,
          1.0212239580495017,
          0.9861580921070916,
          0.9848402781145913,
          0.9887538850307465,
          0.983519434928894,
          0.9754898079804012,
          1.0051498029913222,
          0.9746194566999163,
          1.0404885368687766,
          1.001342928835324,
          0.9653605605874743,
          0.9587705529161862,
          0.9829806025539126,
          1.0088074888501848,
          0.9718903047697884,
          0.9937519431114197,
          0.959692337683269,
          0.9818674474954605,
          0.957768691437585,
          0.9780152184622628,
          0.9578470609017781,
          0.9541112993444715,
          0.9172504075935909,
          0.9501090049743652,
          0.9107477409499032,
          0.9482211130005973,
          0.9002273338181632,
          0.9190582207271031,
          0.9254614753382546,
          0.9115953658308301,
          0.9029047851051603,
          0.8934152892657689,
          0.8681901682700429,
          0.9081149016107831,
          0.8900678072656903,
          0.919180589062827,
          0.898737085717065,
          0.8977561848504203,
          0.8444773959262031,
          0.8970329633780888,
          0.8844057321548462,
          0.870432470526014,
          0.8616457624094827,
          0.8793591601508004,
          0.8808800556829998,
          0.8610760250261852,
          0.8699460306337902,
          0.8734905613320214,
          0.891848657812391,
          0.8890664960656848,
          0.8765330740383693,
          0.8423806173460824,
          0.8755228391715458,
          0.8690560183354786,
          0.8994559134755816,
          0.8987563082150051,
          0.8650698406355721,
          0.8678934574127197,
          0.8454782281603131,
          0.8607950593744006,
          0.8365223514182227,
          0.87557467179639,
          0.8379371251378741,
          0.878333044903619,
          0.8464100978204182,
          0.9180367461272648,
          0.8719540685415268,
          0.8316022327968052,
          0.8841525380100522,
          0.8552754414933068,
          0.8719755624021802,
          0.8812667323010308,
          0.8552518295390266,
          0.8715566141264779,
          0.8906500807830265,
          0.8654280773230961,
          0.8339454297508512,
          0.8637968259198325,
          0.8290644713810512,
          0.8684108832052776,
          0.881237947515079,
          0.8479073132787432,
          0.8640384588922773,
          0.8530601944242205,
          0.8439714695726123,
          0.8659854978322983,
          0.820358408348901,
          0.8544350415468216,
          0.856638735958508,
          0.8593187289578574,
          0.8673412714685712,
          0.8625451092209134,
          0.8397357038089207,
          0.8461766626153674,
          0.8708796203136444,
          0.8699567360537392,
          0.8364364462239402,
          0.8439377333436694,
          0.8427567056247166,
          0.848456186907632,
          0.8555638577256884,
          0.8626207709312439,
          0.8611514163868768,
          0.8300978754247937,
          0.8590102408613477,
          0.8399920357125146,
          0.8795665672847203,
          0.8470622045653207,
          0.8228845447301865,
          0.8291842362710408,
          0.8371205670492989,
          0.8667414997305188,
          0.8595812916755676,
          0.8351215720176697,
          0.8708228873355048,
          0.8391670797552381,
          0.8764516370637077,
          0.8356828987598419,
          0.8509880730084011,
          0.8473865304674421,
          0.8338717179638999,
          0.8278146748031888,
          0.8545114057404655,
          0.863051352756364,
          0.8434753034796033,
          0.8652077210800988,
          0.8600522960935321,
          0.8433042636939457,
          0.8716790314231601,
          0.8321552446910313,
          0.8392575191599982,
          0.865790035043444,
          0.8306529436792646,
          0.8513677950416293,
          0.8377618789672852,
          0.8770982974341938,
          0.8728129118680954,
          0.8370657201324191,
          0.8580752057688577,
          0.8490869935069766,
          0.8477518899100167,
          0.8622257730790547,
          0.8391258759157998,
          0.8439595656735557,
          0.8533208327633994,
          0.881856980068343,
          0.8673950880765915,
          0.8449051380157471,
          0.8450783980744225,
          0.8465401956013271,
          0.8543287622077125,
          0.8591612300702504,
          0.85750093630382,
          0.8310632641826358,
          0.8397639351231712,
          0.8442494017737252,
          0.8455536620957511,
          0.8761345765420369,
          0.859351824436869,
          0.8644547015428543,
          0.8289180227688381,
          0.8282794058322906,
          0.8382210944380079,
          0.8387077706200736,
          0.840090491941997,
          0.8348117555890765,
          0.8653862923383713,
          0.8487565261977059,
          0.8293958987508502,
          0.8805708353008542,
          0.8533414644854409,
          0.8287143579551152,
          0.8499386544738498,
          0.8314840985195977,
          0.8404405883380345,
          0.839387025151934,
          0.8367958856480462,
          0.8242924128259931,
          0.8442011432988303,
          0.8502910296831813,
          0.8789469322987965,
          0.8339440311704364,
          0.8355871055807386,
          0.8272085998739515,
          0.8376500500099999,
          0.848726430109569,
          0.8397189400025776,
          0.8577980484281268,
          0.845924626503672,
          0.828705180968557,
          0.8461181436266217,
          0.8352499370064054,
          0.8405488708189556,
          0.8474631884268352,
          0.8456667640379497,
          0.8452799575669425,
          0.8469483107328415,
          0.8625599273613521,
          0.8613769369465964,
          0.8372247431959424,
          0.845728840146746,
          0.831605498279844,
          0.8657485097646713,
          0.8259661367961338,
          0.8478847039597375,
          0.8319940439292363,
          0.8670645100729806,
          0.8542061341660363,
          0.8332002141645977,
          0.8502466529607773,
          0.8641606739589146,
          0.8349999040365219,
          0.8453717465911593,
          0.8295574220163482,
          0.8603071910994393,
          0.84316143819264,
          0.8492208846977779,
          0.8504606464079448,
          0.8335104542119163,
          0.8515844685690743,
          0.8301233521529606,
          0.8580954564469201,
          0.8410657814570835,
          0.849728599190712,
          0.8482769748994282,
          0.827153029186385,
          0.8699276851756232,
          0.8333817315953118,
          0.8302229579005923,
          0.8846352164234433,
          0.8153921748910632,
          0.8377633605684552,
          0.85354083776474,
          0.8378434138638633,
          0.8337118136031287,
          0.836603541459356,
          0.8418093600443431,
          0.7768573675836835,
          0.8461836917059762,
          0.8273083695343563,
          0.8616755775042942,
          0.8240676288093839,
          0.8320990886007037,
          0.8475813801799502,
          0.8647245360272271,
          0.8237096603427615,
          0.8776224894183022,
          0.8408207382474627,
          0.8595447966030666,
          0.8513595291546413,
          0.8786198454243797,
          0.835866025515965,
          0.8400328095470156,
          0.8280994274786541,
          0.824681601354054,
          0.8325120380946568,
          0.8315862502370562,
          0.8877155759504863,
          0.896015641944749,
          0.819915349994387,
          0.8673698838268008,
          0.8474304165158953,
          0.8358740359544754,
          0.8348067147391183,
          0.8358205599444253,
          0.8320944798844201,
          0.8758565783500671,
          0.8519424242632729,
          0.8179125913551876,
          0.8339982373373849,
          0.9005275347403118,
          0.8581930271216801,
          0.8693588525056839,
          0.8193926279033933,
          0.8367341458797455,
          0.8446573274476188,
          0.8425874624933515,
          0.8261925173657281,
          0.8538209753377097,
          0.8328585688556943,
          0.873251844729696,
          0.8275384434631893,
          0.8700472904103143,
          0.8476684370211193,
          0.8399204782077244,
          0.8367153470005307,
          0.8361641253743853,
          0.8480123366628375,
          0.8530810496636799,
          0.8356582266943795,
          0.8543260416814259,
          0.8341599809271949,
          0.836800788130079,
          0.8525420746632985,
          0.847338250705174,
          0.8532841120447431,
          0.8795161289828164,
          0.8281610586813518,
          0.8416149169206619,
          0.8475935139826366,
          0.8403339598860059,
          0.8194643088749477,
          0.8445356679814202,
          0.8392163280929837,
          0.8407565653324127,
          0.8317424654960632,
          0.8173444611685616,
          0.8569540509155819,
          0.8222266095025199,
          0.8349143585988453,
          0.8211348823138646,
          0.8319476523569652,
          0.835104661328452,
          0.8909308803933007,
          0.8575245652879987,
          0.8412282764911652,
          0.8326930914606366,
          0.843521637575967,
          0.8214286650930133,
          0.8206996470689774,
          0.8531402690070016,
          0.8534605226346424,
          0.8478903834308896,
          0.824274114200047,
          0.8314734314169202,
          0.8634811341762543,
          0.8678165610347476,
          0.8269844331911632,
          0.8299338519573212,
          0.8385201820305416,
          0.8406389696257455,
          0.8506652010338647,
          0.8605934370841298,
          0.8591560614960534,
          0.8347904128687722,
          0.8252141326665878,
          0.8364132844976017,
          0.8396916815212795,
          0.8265166963849749,
          0.8246535211801529,
          0.8673980512789318,
          0.8211489021778107,
          0.8635922606502261,
          0.8221425073487418,
          0.8231190464326313,
          0.8258479876177651,
          0.8339264882462365,
          0.8653492650815419,
          0.8461417853832245,
          0.8275000602006912,
          0.8425970460687365,
          0.8270653656550816,
          0.8249665456158775,
          0.825566186436585,
          0.8435163902384895,
          0.8188338684184211,
          0.8791450772966657,
          0.8310948929616383,
          0.86512098887137,
          0.8695547452994755,
          0.840292506984302,
          0.8270801241908755,
          0.830491419349398,
          0.8539752513170242,
          0.8416095950773784,
          0.8579234608582088,
          0.8521030832614217,
          0.8479883202484676,
          0.8304628772394997,
          0.8308009377547673,
          0.8360368247543063,
          0.8280737825802394,
          0.8448606325047356,
          0.809073194861412,
          0.8322393063988004,
          0.8328699086393628,
          0.8262845192636762,
          0.8606083776269641,
          0.8391210660338402,
          0.8199780264071056,
          0.8525063672236034,
          0.8458611007247653,
          0.8332452923059464,
          0.8364697311605725,
          0.8390391852174487,
          0.8411858496921403,
          0.8271997783865247,
          0.8340814624513898,
          0.8756842655794961,
          0.8209229132958821,
          0.8352821724755424,
          0.8318350059645516,
          0.8540855177811214,
          0.847297306571688,
          0.8299131436007363,
          0.8289267867803574,
          0.8398183626788003,
          0.8234390829290662,
          0.8494152128696442,
          0.8567610106297902,
          0.8300123661756516,
          0.8337184659072331,
          0.8480884049619947,
          0.8309852268014636,
          0.8153181629521506,
          0.83840526001794,
          0.8279273360967636,
          0.852178794997079,
          0.8239132251058306,
          0.8341342998402459,
          0.8362556781087603,
          0.8603115273373467,
          0.8307530454226902,
          0.8243617010968072,
          0.8168724306992122,
          0.8372806651251656,
          0.8376174207244601,
          0.820555065359388,
          0.8330191927296775,
          0.8424422826085772,
          0.8205939701625279,
          0.8321657074349267,
          0.8218375891447067,
          0.8266224967581886,
          0.8305532783269882,
          0.8733492365905217,
          0.8300213686057499,
          0.8482787949698312,
          0.8267832973173687,
          0.8354344836303166,
          0.8373960980347225,
          0.833268478512764,
          0.8098944021122796,
          0.8370464316436222,
          0.8387864232063293,
          0.8533097377845219,
          0.8399079442024231,
          0.8263268896511623,
          0.8140700587204525,
          0.8337413306747165,
          0.8211348248379571,
          0.8288008230073112,
          0.828441566654614,
          0.8200622243540627,
          0.8349231438977378,
          0.8146973422595433,
          0.9408053883484432,
          0.8214559384754726,
          0.8605726936033794,
          0.8297783476965768,
          0.8440787281308856,
          0.8872685049261365,
          0.8432519350733075,
          0.8346123844385147,
          0.8439028986862728,
          0.8499830663204193,
          0.8381911111729485,
          0.8137396233422416,
          0.8173921001808984,
          0.8408479541540146,
          0.8072215254817691,
          0.8808012093816485,
          0.8273005953856877,
          0.8235731295176915,
          0.834257362144334,
          0.8327679974692208,
          0.839731582573482,
          0.8268593677452633,
          0.7965684533119202,
          0.8408873230218887,
          0.8299382903746196,
          0.8823376425674984,
          0.8360590296132224,
          0.8410730510950089,
          0.8750745526381901,
          0.8424376462187085,
          0.8273210717099053,
          0.825008322085653,
          0.8766219019889832,
          0.8335928916931152,
          0.8531285609517779,
          0.8353385840143476,
          0.8403664061001369,
          0.8158009754759925,
          0.8312054936374936,
          0.7908123561314174,
          0.8313108682632446,
          0.8434120203767504,
          0.8300417980977467,
          0.8154819416148322,
          0.8129823857120105,
          0.8382545709609985,
          0.8068120564733233,
          0.8391040010111672,
          0.8600047209433147,
          0.8251436097281319,
          0.8501501828432083,
          0.852191897375243,
          0.8468421527317592,
          0.8111250145094735,
          0.8217431306838989,
          0.8360608092376164,
          0.8425323814153671,
          0.841627972466605,
          0.8485050435577121,
          0.864866561123303,
          0.8417002537420818,
          0.8313320704868862,
          0.8325631959097726,
          0.8568731035505023,
          0.8511651200907571,
          0.7973845462713923,
          0.8562583146350724,
          0.8513544095414025,
          0.8388960106032235,
          0.81078069124903,
          0.8071131088903972,
          0.8306755338396344,
          0.8098020702600479,
          0.8377516269683838,
          0.8441307033811297,
          0.7545590549707413,
          0.8001485637256077,
          0.7623507933957236,
          0.7952587221349988,
          0.8551093127046313,
          0.8032898924180439,
          0.8462529650756291,
          0.8306434878281185,
          0.8061615611825671,
          0.7918679565191269,
          0.8203939412321363,
          0.801625377365521,
          0.7366141974925995,
          0.8214376739093235,
          0.8414479323795864,
          0.8305699186665672,
          0.7782430180481502,
          0.8030404810394559,
          0.8647088153021676,
          0.7318364892687116,
          0.7713123091629573,
          0.7054429139409747,
          0.770806976727077,
          0.7291272431612015,
          0.8403261261326926,
          0.8398175644023078,
          0.7351907406534467,
          0.7572023357663836,
          0.7520750122410911,
          0.7447946880544934,
          0.7459215138639722,
          0.6813713546310153,
          0.7548013978770801,
          0.6718055989061084,
          0.6973415166139603,
          0.6598283776215145,
          0.6529291165726525,
          0.7000085562467575,
          0.618953253541674,
          0.6971285768917629,
          0.6862976082733699,
          0.7057063281536102,
          0.6282292072262082,
          0.6421935089996883,
          0.6498270737273353,
          0.6392309154782977,
          0.6481311704431262,
          0.6293882344450269,
          0.6430662402084896,
          0.6310239604541233,
          0.6174649915524891,
          0.6114082293851035,
          0.6071676739624569,
          0.645934922354562,
          0.6046104942049298,
          0.5954670054571969,
          0.6161854692867824,
          0.5711498941693988,
          0.6685334720781871,
          0.686468745980944,
          0.6327273632798877,
          0.5780864911420005,
          0.6481095807892936,
          0.6123247678790774,
          0.5778736493417195,
          0.6021125444344112,
          0.6042636122022357,
          0.5951489827462605,
          0.6274046323129109,
          0.5864351136343819,
          0.6037257994924273,
          0.5980388032538551,
          0.597566545009613,
          0.5813154663358416,
          0.5824341880423682,
          0.6012660286256245,
          0.5732583552598953,
          0.5839446868215289,
          0.550904206931591,
          0.5791454953806741,
          0.6704998569829124,
          0.589878648519516,
          0.6162212533610207,
          0.57260412722826,
          0.5949809934411731,
          0.6342584810086659,
          0.5982053663049426,
          0.5641190877982548,
          0.5869279461247581,
          0.5631312962089267,
          0.5712208875588008,
          0.6037842833570072,
          0.5753348491021565,
          0.5694733070475715,
          0.599645829626492,
          0.6482517101934978,
          0.5723505616188049,
          0.6066607641322272,
          0.6051201969385147,
          0.5515145797814641,
          0.53640558889934,
          0.6026192115885871,
          0.6439511775970459,
          0.5555068616356168,
          0.5811997864927564,
          0.5529061875173024,
          0.5566511494772775,
          0.5432069280317852,
          0.644483357667923,
          0.557987025805882,
          0.5647425119365964,
          0.5664801225066185,
          0.5575048157146999,
          0.563115982072694,
          0.5848572658640998,
          0.5637152556862149,
          0.6328373806817191,
          0.5678799322673252,
          0.5666073592645782,
          0.559977861387389,
          0.5539275641952243,
          0.5418832993933133,
          0.5691377126744815,
          0.5679663643240929,
          0.5590103949819293,
          0.5125230806214469,
          0.5524799089346614,
          0.5414616124970573,
          0.4801479216132845,
          0.5790654761450631,
          0.6217370118413653,
          0.5089008339813778,
          0.4682500830718449,
          0.5937651331935611,
          0.5461805377687726,
          0.500298872590065,
          0.6294343279940742,
          0.6478614466530936,
          0.505349657365254,
          0.5223486827952522,
          0.5475849147353854,
          0.5665402497564044,
          0.5544525235891342,
          0.5413289325577872,
          0.5520491408450263,
          0.6345106565526554,
          0.5797202800001416,
          0.5290310446705137,
          0.5056953323738915,
          0.5587870265756335,
          0.6506333532077926,
          0.5507692503077644,
          0.5481954451118197,
          0.564637548157147,
          0.6801724008151463,
          0.5849896669387817,
          0.545618766120502,
          0.5140379454408374,
          0.5654749018805367,
          0.5718002170324326,
          0.49904035883290426,
          0.5643806606531143,
          0.49441772273608614,
          0.5346797555685043,
          0.531785820211683,
          0.5292258954473904,
          0.5204594390732902,
          0.43709790068013327,
          0.4844501795513289,
          0.5694615095853806,
          0.5159247709172112,
          0.5379964943443026,
          0.5310438999107906,
          0.5498935878276825,
          0.4532618022390774,
          0.5285525513546807,
          0.5144427929605756,
          0.5319824644497463,
          0.44990668978009907,
          0.5300853103399277,
          0.44794605459485737,
          0.5340767396347863,
          0.6771326959133148,
          0.5436761613403048,
          0.6546517546687808,
          0.5372282905238015,
          0.5302287851061139,
          0.5798674012933459,
          0.5516371599265507,
          0.5473251342773438,
          0.5373339035681316,
          0.5372688812868935,
          0.5369762309959957,
          0.523639087166105,
          0.5394697508641652,
          0.5644948567662921,
          0.5298678236348289,
          0.4986143112182617,
          0.5300403854676655,
          0.5878469092505318,
          0.537148226584707,
          0.5829465218952724,
          0.5761536508798599,
          0.6600960620812008,
          0.5366304644516536,
          0.6154523236410958,
          0.5412293310676303,
          0.6851485180003303,
          0.5453126409224102,
          0.4633561841079167,
          0.5046378565686089,
          0.5615494911159787,
          0.6809699152197156,
          0.559090854866164,
          0.5795550133500781,
          0.5449889728001186,
          0.5553238796336311,
          0.5371854688440051,
          0.5419745892286301,
          0.6145610426153455,
          0.5294282287359238,
          0.5351505662713733,
          0.5462705365249089,
          0.5392210483551025,
          0.5318985155650547,
          0.5991444396121162,
          0.5169757402368954,
          0.5428096204996109,
          0.5501818954944611,
          0.5380518053259168,
          0.5299131189073835,
          0.5071843287774495,
          0.5100746516670499,
          0.4788286047322409,
          0.6027928931372506,
          0.5271542987653187,
          0.5224528227533612,
          0.5455549721206937,
          0.5547957292624882,
          0.5323075779846737,
          0.5543176446642194,
          0.5283164637429374,
          0.5183382332324982,
          0.5185865589550563,
          0.5158668692622866,
          0.5576904990843364,
          0.41721063000815256,
          0.49053163613591877,
          0.5157421550580433,
          0.49657377174922396,
          0.49180605156081064,
          0.6549984642437526,
          0.49788782000541687,
          0.5171573502676827,
          0.5415339001587459,
          0.5298023798636028,
          0.5266031814473016,
          0.5124345975262778,
          0.5339603466647012,
          0.5199388372046607,
          0.4945389862571444,
          0.5071448236703873,
          0.5177449988467353,
          0.5715153770787376,
          0.4261272145169122,
          0.5694301554134914,
          0.5384999258177621,
          0.51352830018316,
          0.5243355631828308,
          0.6116185805627278,
          0.5206532563482013,
          0.598165722829955,
          0.5153874094997134,
          0.554651894739696,
          0.5492954403162003,
          0.5430773283754077,
          0.5261557889836175,
          0.5523898878267833,
          0.5253934562206268,
          0.5183065522994313,
          0.5207402578422001,
          0.5169631923948016,
          0.5463224542992455,
          0.5960891033921923,
          0.5377280009644372,
          0.5135991999081203,
          0.5262118343796048,
          0.5567213829074588,
          0.5029759513480323,
          0.49873448482581545,
          0.49683154693671633,
          0.5148285904100963,
          0.4974650485174997,
          0.48564083129167557,
          0.5330795007092612,
          0.5093717617647988,
          0.4802195004054478,
          0.5253258390086037,
          0.6401313671043941,
          0.4133791242327009,
          0.4836546352931431,
          0.4414873038019453,
          0.49197420477867126,
          0.5200488993099758,
          0.6083833681685584,
          0.5455295102936881,
          0.5109619327953884,
          0.5875174765075956,
          0.5174714412008014,
          0.5340747279780251,
          0.5048109026891845,
          0.6591052093676159,
          0.5122072654111045,
          0.5381992970194135,
          0.5135214584214347,
          0.5170873339687075,
          0.5148092082568577,
          0.5227795945746558,
          0.5260243394545147,
          0.5213058846337455,
          0.5228640990597861,
          0.4879432831491743,
          0.5517078701938901,
          0.5279470639569419,
          0.5367719424622399,
          0.5228907423360007,
          0.5200430750846863,
          0.4897871581571443,
          0.530807226896286,
          0.5148868241480419,
          0.5217330349343163,
          0.514487732733999,
          0.5649891453129905,
          0.517546051314899,
          0.5321045645645687,
          0.5093459508248738,
          0.5142525030033929,
          0.531193169099944,
          0.5868580979960305,
          0.4878433144518307,
          0.5298286633832114,
          0.5361807261194501,
          0.5089492414678846,
          0.5145635775157383,
          0.45747779309749603,
          0.5100117815392358,
          0.5086897036858967,
          0.5459714702197483,
          0.5848148358719689,
          0.5310536921024323,
          0.49561311304569244,
          0.48552788155419485,
          0.5147488159792764,
          0.550487580043929,
          0.5473470432417733,
          0.5215936728886196,
          0.526948732989175,
          0.5140895055873054,
          0.4576023817062378,
          0.49928404816559385,
          0.5056020468473434,
          0.5116005135434014,
          0.5593318726335254,
          0.41362723069531576,
          0.520998056445803,
          0.5213392930371421,
          0.5250849319355828,
          0.5143394640513829,
          0.5098820818322045,
          0.5238789788314274,
          0.5185559072664806,
          0.5443127644913537,
          0.5017187233482089,
          0.5147931086165565,
          0.525936701468059,
          0.45284061985356466,
          0.49703243587698254,
          0.5082583171980721,
          0.4935908849750246,
          0.5284467956849507,
          0.4908643939665386,
          0.48637802047388895,
          0.4957630197916712,
          0.5414174773863384,
          0.5123740562370845,
          0.4934160624231611,
          0.4883576865707125,
          0.5987934193440846,
          0.5095955729484558,
          0.5381634426968438,
          0.4874314091035298,
          0.5128751184259143,
          0.5069750717708043,
          0.47113569719450815,
          0.5050252654722759,
          0.49936539573328836,
          0.534159813608442,
          0.5068838426045009,
          0.49493978704724995,
          0.5588614834206445,
          0.5488363280892372,
          0.5476186509643283,
          0.5294756101710456,
          0.5680934914520809,
          0.506601061139788,
          0.5121231951883861,
          0.509031104190009,
          0.4886299648455211,
          0.542135917714664,
          0.48007417789527346,
          0.5127659301672663,
          0.42813424446753096,
          0.4382248286690031,
          0.4701887922627585,
          0.5271703324147633,
          0.4692399672099522,
          0.4343863236052649,
          0.5334574303456715,
          0.5467899143695831,
          0.520741588303021,
          0.5428877685751233,
          0.5331156935010638,
          0.4923280051776341,
          0.5510510121073041,
          0.47975542076996397,
          0.5110625582081931,
          0.4552802102906363,
          0.4798302948474884,
          0.44430445560387205,
          0.4495241343975067,
          0.5529172463076455,
          0.6308276248829705,
          0.5042318488870349,
          0.5308753486190524,
          0.5205377851213727,
          0.5444524905511311,
          0.47931936170373646,
          0.4882991590670177
         ]
        },
        {
         "line": {
          "color": "firebrick",
          "dash": "dash",
          "width": 2
         },
         "mode": "lines",
         "name": "Validation Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000
         ],
         "y": [
          0.8278348743915558,
          0.7686606347560883,
          0.7376874387264252,
          0.7299588024616241,
          0.7232449054718018,
          0.7260010242462158,
          0.7258867621421814,
          0.7245519161224365,
          0.7288261950016022,
          0.7271969020366669,
          0.720848798751831,
          0.7205073833465576,
          0.7158222496509552,
          0.7090095579624176,
          0.7146870791912079,
          0.7131409645080566,
          0.7152579724788666,
          0.7105259895324707,
          0.7134566605091095,
          0.720285952091217,
          0.7319561839103699,
          0.7188790738582611,
          0.7156244516372681,
          0.7145029902458191,
          0.7123593389987946,
          0.7203174531459808,
          0.7269194722175598,
          0.7349896132946014,
          0.72318235039711,
          0.7171217799186707,
          0.7221432328224182,
          0.7307636439800262,
          0.7285703420639038,
          0.7122047245502472,
          0.7093095779418945,
          0.7112276256084442,
          0.7212437987327576,
          0.7229335308074951,
          0.7199385762214661,
          0.7146459817886353,
          0.7198486626148224,
          0.7119578719139099,
          0.7137674689292908,
          0.7134000062942505,
          0.7197326719760895,
          0.7148887813091278,
          0.7136189937591553,
          0.7140375673770905,
          0.7179484069347382,
          0.7148887813091278,
          0.7268534004688263,
          0.7281098067760468,
          0.7226538956165314,
          0.718187153339386,
          0.7203340232372284,
          0.7151564657688141,
          0.710903525352478,
          0.7114831507205963,
          0.7205161154270172,
          0.7164856791496277,
          0.7166485488414764,
          0.710067629814148,
          0.7037800848484039,
          0.7141223251819611,
          0.7144362032413483,
          0.7081880867481232,
          0.6937542259693146,
          0.692164957523346,
          0.6977032721042633,
          0.7130659520626068,
          0.7076059579849243,
          0.6905277669429779,
          0.6947270035743713,
          0.6914339661598206,
          0.6906296014785767,
          0.7052802741527557,
          0.7065072357654572,
          0.6973403096199036,
          0.6899025440216064,
          0.6916299760341644,
          0.6975851058959961,
          0.6960112452507019,
          0.6886034607887268,
          0.6892913579940796,
          0.6980552077293396,
          0.7007730901241302,
          0.6901628971099854,
          0.6913166642189026,
          0.6972047686576843,
          0.6934682428836823,
          0.6892717182636261,
          0.6881929934024811,
          0.6903879642486572,
          0.6948194801807404,
          0.7071746289730072,
          0.690157562494278,
          0.6868734359741211,
          0.6906956434249878,
          0.696749746799469,
          0.6908653676509857,
          0.6985441148281097,
          0.6924754679203033,
          0.6890358030796051,
          0.6903959214687347,
          0.6908636093139648,
          0.6965913772583008,
          0.6949149072170258,
          0.6986134052276611,
          0.6997851729393005,
          0.7019342482089996,
          0.6905524134635925,
          0.6928335726261139,
          0.6944239139556885,
          0.6944457590579987,
          0.6941855549812317,
          0.6965124905109406,
          0.6956087946891785,
          0.6943753361701965,
          0.6943327784538269,
          0.6947683990001678,
          0.6995197534561157,
          0.697986364364624,
          0.699125736951828,
          0.6984091997146606,
          0.6901974976062775,
          0.69001904129982,
          0.6966666877269745,
          0.6996953785419464,
          0.6922189295291901,
          0.6911463439464569,
          0.6941334009170532,
          0.696643739938736,
          0.7035782635211945,
          0.6979052722454071,
          0.6961683034896851,
          0.6977160274982452,
          0.6966268718242645,
          0.6968535780906677,
          0.6937319934368134,
          0.6980629861354828,
          0.697850227355957,
          0.698944479227066,
          0.6927548050880432,
          0.6917450428009033,
          0.6945956647396088,
          0.6943972706794739,
          0.6950726509094238,
          0.6959120035171509,
          0.6971425116062164,
          0.6910020411014557,
          0.6881975531578064,
          0.6874435842037201,
          0.7040838301181793,
          0.7098511755466461,
          0.6896898150444031,
          0.6850306689739227,
          0.68844935297966,
          0.6945348083972931,
          0.699181854724884,
          0.6986241340637207,
          0.6987221240997314,
          0.6958238184452057,
          0.69415283203125,
          0.6956729590892792,
          0.6976534724235535,
          0.6955068409442902,
          0.696716845035553,
          0.7065440118312836,
          0.7117558121681213,
          0.7033417820930481,
          0.6981519460678101,
          0.693220466375351,
          0.6957801580429077,
          0.6977152228355408,
          0.6937060058116913,
          0.6959917545318604,
          0.6954731345176697,
          0.692799836397171,
          0.6907188594341278,
          0.6922712028026581,
          0.6950271725654602,
          0.698602020740509,
          0.6990407407283783,
          0.6964256167411804,
          0.6939697861671448,
          0.690647304058075,
          0.6937896907329559,
          0.6930290162563324,
          0.6979024410247803,
          0.6987763345241547,
          0.6954691112041473,
          0.6932505369186401,
          0.6958732008934021,
          0.6945300102233887,
          0.6957582533359528,
          0.6926834285259247,
          0.6893091797828674,
          0.6928924918174744,
          0.6969000101089478,
          0.7000267803668976,
          0.7004260718822479,
          0.6971051394939423,
          0.6953145861625671,
          0.6938416659832001,
          0.6949059665203094,
          0.6960454881191254,
          0.6968711912631989,
          0.6962409019470215,
          0.6949398517608643,
          0.6931357681751251,
          0.6960347294807434,
          0.6954771876335144,
          0.6972382068634033,
          0.6997144818305969,
          0.6985794305801392,
          0.6986374855041504,
          0.6964946687221527,
          0.6941839754581451,
          0.6921214163303375,
          0.6902012526988983,
          0.6952331066131592,
          0.6951731443405151,
          0.7015694379806519,
          0.7002609670162201,
          0.6997953653335571,
          0.6965738534927368,
          0.6963441967964172,
          0.6953445076942444,
          0.6965356767177582,
          0.6980787813663483,
          0.6964470744132996,
          0.6955919563770294,
          0.6947684586048126,
          0.696934312582016,
          0.6977764070034027,
          0.6953345239162445,
          0.6983530223369598,
          0.6964088380336761,
          0.6934429407119751,
          0.6925676167011261,
          0.6935696601867676,
          0.6951850056648254,
          0.6955715119838715,
          0.6996074020862579,
          0.7016963064670563,
          0.6974190473556519,
          0.6938735246658325,
          0.6927419304847717,
          0.6941250562667847,
          0.6968544125556946,
          0.696643739938736,
          0.6939349472522736,
          0.6951727867126465,
          0.6958418786525726,
          0.6964758038520813,
          0.6967832148075104,
          0.6978388428688049,
          0.6985190510749817,
          0.6956819593906403,
          0.6897456645965576,
          0.6914437115192413,
          0.6923956573009491,
          0.694656252861023,
          0.6954678297042847,
          0.698736846446991,
          0.7028985917568207,
          0.6981813907623291,
          0.6988495588302612,
          0.7014838755130768,
          0.6949641108512878,
          0.6922335028648376,
          0.6965182721614838,
          0.6950216889381409,
          0.692317545413971,
          0.6947211027145386,
          0.6990556716918945,
          0.7006530165672302,
          0.6970042884349823,
          0.6929499506950378,
          0.6927698254585266,
          0.6929357349872589,
          0.6949912905693054,
          0.6968003511428833,
          0.7104166150093079,
          0.7103050649166107,
          0.7003439962863922,
          0.6962143182754517,
          0.6951963603496552,
          0.705284059047699,
          0.7108057141304016,
          0.7060830593109131,
          0.6958003342151642,
          0.694076657295227,
          0.6926253736019135,
          0.6965813338756561,
          0.6940205991268158,
          0.6917007267475128,
          0.6927733421325684,
          0.697843611240387,
          0.7034285664558411,
          0.7003954648971558,
          0.6970210373401642,
          0.6953826546669006,
          0.6933634579181671,
          0.6930456161499023,
          0.6961244642734528,
          0.6968284547328949,
          0.696853905916214,
          0.6929823458194733,
          0.6921223700046539,
          0.6920305788516998,
          0.7017634510993958,
          0.7096758484840393,
          0.7053079605102539,
          0.6966062486171722,
          0.6915041208267212,
          0.6891235411167145,
          0.6936177611351013,
          0.695841521024704,
          0.6973280906677246,
          0.6965929269790649,
          0.6996698975563049,
          0.7049830555915833,
          0.7003814876079559,
          0.6965148746967316,
          0.692865252494812,
          0.6929781436920166,
          0.6926466226577759,
          0.696416974067688,
          0.6986526548862457,
          0.6983931064605713,
          0.6912972629070282,
          0.6907904744148254,
          0.6914097666740417,
          0.6964142620563507,
          0.6950170397758484,
          0.6992180645465851,
          0.6947528421878815,
          0.6928216814994812,
          0.693703681230545,
          0.6943077147006989,
          0.6922672986984253,
          0.6951966881752014,
          0.6980561912059784,
          0.7000831365585327,
          0.6919228732585907,
          0.6885477006435394,
          0.6883404552936554,
          0.6947806477546692,
          0.7019080221652985,
          0.7007710635662079,
          0.6933253407478333,
          0.6927211880683899,
          0.6988623440265656,
          0.6989217698574066,
          0.6968971788883209,
          0.6922214925289154,
          0.6937194764614105,
          0.6986354291439056,
          0.6997111439704895,
          0.6989924013614655,
          0.6967507600784302,
          0.6918646395206451,
          0.6956289708614349,
          0.6955982148647308,
          0.6974485814571381,
          0.6983049213886261,
          0.7021569013595581,
          0.6997705698013306,
          0.6955867111682892,
          0.6959135830402374,
          0.6968102753162384,
          0.6995463371276855,
          0.701110452413559,
          0.702930212020874,
          0.7009280622005463,
          0.6984916925430298,
          0.6962139904499054,
          0.6923695206642151,
          0.6974097490310669,
          0.7012282013893127,
          0.6997891664505005,
          0.6984656751155853,
          0.6962055563926697,
          0.6935023665428162,
          0.6915451884269714,
          0.6937200427055359,
          0.6982206702232361,
          0.6956188380718231,
          0.6951564848423004,
          0.693786084651947,
          0.6997026801109314,
          0.6988789141178131,
          0.6970690786838531,
          0.6917248070240021,
          0.6903663873672485,
          0.694622278213501,
          0.7005062103271484,
          0.7032975554466248,
          0.7007305324077606,
          0.7010838687419891,
          0.6940145492553711,
          0.6913606524467468,
          0.691887378692627,
          0.6980302333831787,
          0.7027231156826019,
          0.7021655440330505,
          0.6995462775230408,
          0.6914072334766388,
          0.6907684206962585,
          0.6979369223117828,
          0.6958925426006317,
          0.6925016641616821,
          0.692383885383606,
          0.6939387619495392,
          0.6938349902629852,
          0.6991420686244965,
          0.697667270898819,
          0.7003457546234131,
          0.7008635997772217,
          0.6921283900737762,
          0.6918598115444183,
          0.6948871612548828,
          0.7021577954292297,
          0.6968109309673309,
          0.6916292607784271,
          0.6917707622051239,
          0.6894744634628296,
          0.6951843798160553,
          0.6984098851680756,
          0.6986837089061737,
          0.6969660520553589,
          0.6993215382099152,
          0.6978886723518372,
          0.6972644329071045,
          0.6939315497875214,
          0.6917451918125153,
          0.696885496377945,
          0.7022251188755035,
          0.702425479888916,
          0.7005125284194946,
          0.7011072039604187,
          0.6945550739765167,
          0.6900068521499634,
          0.6915532052516937,
          0.6974322199821472,
          0.7078501582145691,
          0.6950286328792572,
          0.6906902194023132,
          0.689064234495163,
          0.6960877478122711,
          0.6932177841663361,
          0.6963756382465363,
          0.6985193490982056,
          0.6950632631778717,
          0.6946974098682404,
          0.698258101940155,
          0.6993840336799622,
          0.698799341917038,
          0.6991488933563232,
          0.6974864602088928,
          0.6938973069190979,
          0.7011452913284302,
          0.7029443681240082,
          0.7059305310249329,
          0.687152087688446,
          0.6922600865364075,
          0.6994442641735077,
          0.6976083815097809,
          0.694052666425705,
          0.6948968768119812,
          0.6956589221954346,
          0.6932757794857025,
          0.6920144855976105,
          0.696865439414978,
          0.6970123946666718,
          0.6991391181945801,
          0.7021238505840302,
          0.695184051990509,
          0.6940657496452332,
          0.6969618499279022,
          0.7044157683849335,
          0.6961138546466827,
          0.6871991455554962,
          0.6858403980731964,
          0.6880312561988831,
          0.6901615262031555,
          0.7169212400913239,
          0.7202484309673309,
          0.7117905020713806,
          0.7043542563915253,
          0.6985403001308441,
          0.691417396068573,
          0.7124100029468536,
          0.6878935098648071,
          0.6871028244495392,
          0.6901428401470184,
          0.6959038972854614,
          0.6948617696762085,
          0.6928784847259521,
          0.6910323798656464,
          0.6938586533069611,
          0.7034490704536438,
          0.7012925744056702,
          0.6934196352958679,
          0.6933350265026093,
          0.6960956156253815,
          0.6938426196575165,
          0.692701667547226,
          0.6900787949562073,
          0.6937494874000549,
          0.7018426954746246,
          0.7086501717567444,
          0.7074407637119293,
          0.7100583612918854,
          0.7003651261329651,
          0.7013484239578247,
          0.701416939496994,
          0.6999382972717285,
          0.6872019171714783,
          0.6878195703029633,
          0.695978045463562,
          0.6955477893352509,
          0.7009955942630768,
          0.6977508366107941,
          0.6960747539997101,
          0.6934682428836823,
          0.689611941576004,
          0.6955150961875916,
          0.6925879120826721,
          0.7022380232810974,
          0.701180100440979,
          0.6915228068828583,
          0.7061898708343506,
          0.7092548310756683,
          0.6988326609134674,
          0.6912071406841278,
          0.6879088878631592,
          0.6955640912055969,
          0.7016099989414215,
          0.6965609788894653,
          0.6931469440460205,
          0.6990089416503906,
          0.6970546245574951,
          0.6985947489738464,
          0.7043502330780029,
          0.7101273834705353,
          0.6941823661327362,
          0.687984049320221,
          0.6879377365112305,
          0.6900978982448578,
          0.6963581740856171,
          0.6977714002132416,
          0.7012081146240234,
          0.6966417133808136,
          0.6955009698867798,
          0.6889446675777435,
          0.6908615827560425,
          0.6981317400932312,
          0.6954542696475983,
          0.7014954388141632,
          0.6983303725719452,
          0.6956970393657684,
          0.6931498944759369,
          0.703911304473877,
          0.7176714837551117,
          0.7009105086326599,
          0.6942125856876373,
          0.7077415287494659,
          0.696686714887619,
          0.6846035718917847,
          0.6849281787872314,
          0.6897203326225281,
          0.6918355524539948,
          0.6968368291854858,
          0.7022901475429535,
          0.710169106721878,
          0.6954767405986786,
          0.6860435009002686,
          0.6838532835245132,
          0.6875924170017242,
          0.688205361366272,
          0.6950071752071381,
          0.7250996232032776,
          0.7211281061172485,
          0.6930016875267029,
          0.6865448355674744,
          0.6917899549007416,
          0.7001526355743408,
          0.6995199918746948,
          0.7030219435691833,
          0.7020838558673859,
          0.6956339180469513,
          0.6874171793460846,
          0.6923440992832184,
          0.7009361088275909,
          0.702174186706543,
          0.6892613470554352,
          0.686643123626709,
          0.6900369226932526,
          0.6971315145492554,
          0.7033229768276215,
          0.7174316644668579,
          0.7098457217216492,
          0.691116064786911,
          0.6869640648365021,
          0.6904711127281189,
          0.6972038745880127,
          0.7011296451091766,
          0.6987149119377136,
          0.6988797187805176,
          0.701744019985199,
          0.6966906189918518,
          0.6942827701568604,
          0.69623202085495,
          0.6960243284702301,
          0.6948923468589783,
          0.6951914131641388,
          0.6993896663188934,
          0.6988555490970612,
          0.6997998952865601,
          0.7100041806697845,
          0.7028224170207977,
          0.6992233395576477,
          0.6916910111904144,
          0.6887810826301575,
          0.6986126601696014,
          0.7109629213809967,
          0.7086206376552582,
          0.6996141076087952,
          0.6922602355480194,
          0.6902739703655243,
          0.6893567442893982,
          0.6920400261878967,
          0.6968976259231567,
          0.7042178809642792,
          0.7063983082771301,
          0.7073270976543427,
          0.6996248960494995,
          0.6893195807933807,
          0.6885482668876648,
          0.6901367902755737,
          0.7045140266418457,
          0.7200351655483246,
          0.7159654498100281,
          0.7065315246582031,
          0.6952660977840424,
          0.6927397847175598,
          0.695271760225296,
          0.6994419097900391,
          0.6988432705402374,
          0.6972500681877136,
          0.6969168186187744,
          0.7003982663154602,
          0.7026681303977966,
          0.7041013240814209,
          0.6981755197048187,
          0.6910531520843506,
          0.6935456693172455,
          0.6990662813186646,
          0.706068754196167,
          0.7064602375030518,
          0.6981724202632904,
          0.6978682577610016,
          0.6984890699386597,
          0.6994122862815857,
          0.7040065228939056,
          0.7015615105628967,
          0.6997779011726379,
          0.6966812312602997,
          0.700153112411499,
          0.7022113502025604,
          0.7007356584072113,
          0.698898196220398,
          0.6980534195899963,
          0.6963832974433899,
          0.695448637008667,
          0.6949874758720398,
          0.6947425305843353,
          0.6973362565040588,
          0.6972218751907349,
          0.6992915570735931,
          0.6961028873920441,
          0.6977821588516235,
          0.6991671323776245,
          0.703313559293747,
          0.704216718673706,
          0.7019059658050537,
          0.6991457045078278,
          0.694839596748352,
          0.6971056461334229,
          0.7025196552276611,
          0.7075938582420349,
          0.7041584551334381,
          0.699427455663681,
          0.6962660551071167,
          0.6917604207992554,
          0.6914523839950562,
          0.6939201056957245,
          0.7003499269485474,
          0.7040985524654388,
          0.7090546190738678,
          0.713588535785675,
          0.7062906622886658,
          0.6988214552402496,
          0.6949033141136169,
          0.694621354341507,
          0.6962639093399048,
          0.7007166743278503,
          0.7035712003707886,
          0.6963581144809723,
          0.6979823708534241,
          0.7080439031124115,
          0.7094305455684662,
          0.7057112753391266,
          0.7025976181030273,
          0.6994820833206177,
          0.6998845934867859,
          0.6994265615940094,
          0.6994453072547913,
          0.7029296159744263,
          0.7055533826351166,
          0.7078070342540741,
          0.7032517492771149,
          0.6986100375652313,
          0.6952839195728302,
          0.6959427297115326,
          0.6990986764431,
          0.7006796002388,
          0.7005760669708252,
          0.7071155607700348,
          0.7098010182380676,
          0.7035924792289734,
          0.6999982595443726,
          0.6966867446899414,
          0.6998686492443085,
          0.7016375958919525,
          0.7027538120746613,
          0.7016192078590393,
          0.7032853960990906,
          0.7004576325416565,
          0.7044806778430939,
          0.7016041278839111,
          0.7022689282894135,
          0.7079620957374573,
          0.7037915587425232,
          0.6992876529693604,
          0.6972979307174683,
          0.6978588402271271,
          0.6996813118457794,
          0.6982291340827942,
          0.6987327933311462,
          0.6982606053352356,
          0.701364129781723,
          0.7032877802848816,
          0.7021539509296417,
          0.702494889497757,
          0.7049143016338348,
          0.705972820520401,
          0.6976859867572784,
          0.69509357213974,
          0.7014298141002655,
          0.7074027955532074,
          0.7060737311840057,
          0.7078156769275665,
          0.7121408581733704,
          0.7051441073417664,
          0.7015633285045624,
          0.700922280550003,
          0.7068593502044678,
          0.7081514000892639,
          0.7048670649528503,
          0.7008990049362183,
          0.697331964969635,
          0.7191670536994934,
          0.7216561138629913,
          0.7011882364749908,
          0.6960808634757996,
          0.6967393159866333,
          0.6989442706108093,
          0.7028506696224213,
          0.703689455986023,
          0.7035560607910156,
          0.7001400589942932,
          0.7001160681247711,
          0.7030658423900604,
          0.6993659734725952,
          0.7013406157493591,
          0.7017139494419098,
          0.7036361992359161,
          0.7031820118427277,
          0.7043888866901398,
          0.7035944163799286,
          0.705767035484314,
          0.7032803595066071,
          0.7013052999973297,
          0.7026943266391754,
          0.7075058221817017,
          0.7091017961502075,
          0.7089420258998871,
          0.704824298620224,
          0.7025964260101318,
          0.6995323598384857,
          0.6991895735263824,
          0.6992472410202026,
          0.7005577385425568,
          0.7015675902366638,
          0.7051625847816467,
          0.70538529753685,
          0.7014498114585876,
          0.6998739838600159,
          0.7018790543079376,
          0.7026346325874329,
          0.7100039422512054,
          0.7140199840068817,
          0.7078441381454468,
          0.7027437388896942,
          0.7016381025314331,
          0.7023579776287079,
          0.7022500038146973,
          0.7031777203083038,
          0.7025507688522339,
          0.6975758373737335,
          0.6979078054428101,
          0.7001795172691345,
          0.7031813561916351,
          0.7041237056255341,
          0.7053848206996918,
          0.7118023633956909,
          0.708189845085144,
          0.703850269317627,
          0.7039067447185516,
          0.7078737616539001,
          0.7035313844680786,
          0.7011789381504059,
          0.7026681005954742,
          0.707379549741745,
          0.7064020037651062,
          0.7059711813926697,
          0.7040566802024841,
          0.7037919163703918,
          0.7043340802192688,
          0.7051389515399933,
          0.703201413154602,
          0.7011833190917969,
          0.6972245573997498,
          0.6948541700839996,
          0.6958187818527222,
          0.6996959149837494,
          0.7005531489849091,
          0.7015028893947601,
          0.7010131478309631,
          0.7031660974025726,
          0.703638881444931,
          0.7025251984596252,
          0.7043400704860687,
          0.7063483893871307,
          0.7075796723365784,
          0.7029546797275543,
          0.7006354033946991,
          0.7058109045028687,
          0.7118742167949677,
          0.7086193859577179,
          0.7038723230361938,
          0.7034688293933868,
          0.7048883140087128,
          0.7285961806774139,
          0.7310327291488647,
          0.7171903848648071,
          0.7042331695556641,
          0.7003900408744812,
          0.700316458940506,
          0.7044435739517212,
          0.7073382139205933,
          0.7069509327411652,
          0.7051956355571747,
          0.703495442867279,
          0.7042505741119385,
          0.7043817639350891,
          0.7021276354789734,
          0.702875018119812,
          0.705152302980423,
          0.703609049320221,
          0.701733410358429,
          0.6995390355587006,
          0.6989820301532745,
          0.7008328139781952,
          0.7031607627868652,
          0.7069940268993378,
          0.7032912373542786,
          0.7031176388263702,
          0.7027090489864349,
          0.7032126784324646,
          0.7015458047389984,
          0.7070391476154327,
          0.7073052823543549,
          0.705390602350235,
          0.7042992413043976,
          0.7046289145946503,
          0.705438107252121,
          0.6983066499233246,
          0.6976982057094574,
          0.7009209990501404,
          0.7073544859886169,
          0.7095871567726135,
          0.7089894115924835,
          0.7051858007907867,
          0.7012805044651031,
          0.6997191607952118,
          0.7046888172626495,
          0.7081639766693115,
          0.7150091528892517,
          0.7120564579963684,
          0.7049587666988373,
          0.7017771899700165,
          0.7031277716159821,
          0.7070086896419525,
          0.707534909248352,
          0.7084563374519348,
          0.7029275894165039,
          0.6990038752555847,
          0.7006701231002808,
          0.7030865252017975,
          0.704360842704773,
          0.7065338492393494,
          0.7168740928173065,
          0.7124876379966736,
          0.7061135768890381,
          0.7055471241474152,
          0.7079673409461975,
          0.7059092819690704,
          0.7042634189128876,
          0.7037733793258667,
          0.7031277120113373,
          0.7032039165496826,
          0.7017507255077362,
          0.7012727856636047,
          0.7017894983291626,
          0.7043472528457642,
          0.7026785314083099,
          0.7022420465946198,
          0.7059381306171417,
          0.7036249339580536,
          0.7010547518730164,
          0.7006148397922516,
          0.699193686246872,
          0.7021279335021973,
          0.7046364545822144,
          0.7026405036449432,
          0.7031574845314026,
          0.7065458595752716,
          0.710561066865921,
          0.707744836807251,
          0.7050593495368958,
          0.7008423507213593,
          0.7005410492420197,
          0.6994629800319672,
          0.7030129134654999,
          0.7060807049274445,
          0.7071945667266846,
          0.7064758241176605,
          0.7061605751514435,
          0.7082622349262238,
          0.7061434686183929,
          0.706285297870636,
          0.7054673135280609,
          0.7021684646606445,
          0.7011114954948425,
          0.7018564939498901,
          0.7047036290168762,
          0.705175906419754,
          0.7039625942707062,
          0.7034955322742462,
          0.7071649432182312,
          0.7035891711711884,
          0.703134149312973,
          0.7090940177440643,
          0.7035751044750214,
          0.7019668817520142,
          0.7066406905651093,
          0.7091197967529297,
          0.7114925384521484,
          0.7066876590251923,
          0.7051054537296295,
          0.7048459947109222,
          0.7045838236808777,
          0.7045322954654694,
          0.7025922238826752,
          0.7039263248443604,
          0.6999983191490173,
          0.7017508149147034,
          0.704513669013977,
          0.7062879800796509,
          0.7072045803070068,
          0.7105029821395874,
          0.7071792483329773,
          0.7042723000049591,
          0.7020696401596069,
          0.7015357613563538,
          0.7026969790458679
         ]
        }
       ],
       "layout": {
        "legend": {
         "orientation": "h",
         "x": 1,
         "xanchor": "right",
         "y": 1.02,
         "yanchor": "bottom"
        },
        "margin": {
         "b": 40,
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training & Validation Loss over 100 Epochs"
        },
        "xaxis": {
         "tickfont": {
          "size": 10
         },
         "tickmode": "array",
         "tickvals": [
          0,
          100,
          200,
          300,
          400,
          500,
          600,
          700,
          800,
          900,
          1000
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "gridcolor": "lightgray",
         "tickformat": ".4f",
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "epochs = list(range(1, len(train_losses) + 1))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Training loss trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=train_losses,\n",
    "    mode=\"lines\",\n",
    "    name=\"Training Loss\",\n",
    "    line=dict(color=\"royalblue\", width=2)\n",
    "))\n",
    "\n",
    "# Validation loss trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=val_losses,\n",
    "    mode=\"lines\",\n",
    "    name=\"Validation Loss\",\n",
    "    line=dict(color=\"firebrick\", width=2, dash=\"dash\")\n",
    "))\n",
    "\n",
    "# Layout enhancements\n",
    "fig.update_layout(\n",
    "    title=\"Training & Validation Loss over 100 Epochs\",\n",
    "    xaxis_title=\"Epoch\",\n",
    "    yaxis_title=\"Loss\",\n",
    "    xaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=list(range(0, 1001, 100)),  # Show ticks every 10 epochs\n",
    "        tickfont=dict(size=10)\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickformat=\".2e\" if max(train_losses + val_losses) > 1e4 else \".4f\",  # Dynamic formatting\n",
    "        gridcolor=\"lightgray\"\n",
    "    ),\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1\n",
    "    ),\n",
    "    template=\"plotly_white\",\n",
    "    margin=dict(t=60, b=40)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7adb958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (original units): 201.05\n",
      "RMSE (original units): 342.08\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Collect predictions and true values from the validation set\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_categ, x_numer, target in val_loader:\n",
    "        preds = model(x_categ, x_numer).squeeze().cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "# Inverse-transform predictions and targets to original units\n",
    "preds_orig = scaler_y.inverse_transform(all_preds.reshape(-1, 1)).flatten()\n",
    "targets_orig = scaler_y.inverse_transform(all_targets.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate MAE and RMSE in original units\n",
    "mae = mean_absolute_error(targets_orig, preds_orig)\n",
    "rmse = np.sqrt(mean_squared_error(targets_orig, preds_orig))\n",
    "\n",
    "print(f\"MAE (original units): {mae:.2f}\")\n",
    "print(f\"RMSE (original units): {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ef4cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#regressor.fit(X_train, y_train)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#predictions = regressor.predict(X_dev)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_dev, \u001b[43mpredictions\u001b[49m)\n\u001b[0;32m      6\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mse)\n\u001b[0;32m      7\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(y_dev, predictions)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "predictions = regressor.predict(X_dev)\n",
    "\n",
    "mse = mean_squared_error(y_dev, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_dev, predictions)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"RÂ² Score:\", r2)\n",
    "\n",
    "abs_errors = np.abs(predictions - y_dev)\n",
    "sorted_errors = np.sort(abs_errors)\n",
    "cdf = np.arange(1, len(sorted_errors)+1) / len(sorted_errors)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(sorted_errors, cdf, marker='.', linestyle='none')\n",
    "plt.xlabel('Absolute Error |y_pred - y_true|')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.title('Cumulative Distribution Function (CDF) of Absolute Errors')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60cbd7c",
   "metadata": {},
   "source": [
    "## Coefficient of Determination (RÂ²)\n",
    "\n",
    "The coefficient of determination, denoted as $( R^2 )$, is a commonly used metric to evaluate the performance of a regression model. It indicates how well the model explains the variance in the target variable \\( y \\).\n",
    "\n",
    "### Definition\n",
    "\n",
    "The formula for $( R^2 )$ is:\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{SS_{\\text{res}}}{SS_{\\text{tot}}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $( SS_{\\text{res}} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2)$: Residual Sum of Squares (model error)\n",
    "-  $(SS_{\\text{tot}} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2)$: Total Sum of Squares (total variance in the data)\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- $( R^2 = 1)$: Perfect prediction â€“ the model explains 100% of the variance in $( y)$\n",
    "- $( R^2 = 0)$: The model does no better than simply predicting the mean of $( y )$\n",
    "- $( R^2 < 0 )$: The model performs worse than a constant mean prediction\n",
    "\n",
    "### Example\n",
    "\n",
    "In this case, the model achieved an $( R^2 )$ score of **0.61**, which means it explains **61% of the total variance** in the target variable.\n",
    "\n",
    "This is a moderate-to-good result, indicating that the model captures significant patterns in the data, but there is still room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1324ff",
   "metadata": {},
   "source": [
    "## Mean Squared Error (MSE)\n",
    "\n",
    "The **Mean Squared Error (MSE)** is a standard regression metric that measures the average of the squared differences between the predicted values and the actual target values.\n",
    "\n",
    "### Definition\n",
    "\n",
    "$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $y_i$: true value  \n",
    "- $\\hat{y}_i$: predicted value  \n",
    "- $n$: number of samples\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- MSE penalizes larger errors more strongly due to squaring.\n",
    "- The result is in the **squared unit** of the target variable (e.g., mmÂ², NÂ², â‚¬Â²).\n",
    "- A **lower MSE** indicates better prediction accuracy.\n",
    "- Because of squaring, the MSE is sensitive to **outliers**.\n",
    "\n",
    "### Example\n",
    "\n",
    "In this case, the model yielded an MSE of **88,837**, which may seem large, but this must be interpreted in the context of the unit and range of the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea33823",
   "metadata": {},
   "source": [
    "## Root Mean Squared Error (RMSE)\n",
    "\n",
    "The **Root Mean Squared Error (RMSE)** is the square root of the MSE and represents the average prediction error in the same unit as the target variable.\n",
    "\n",
    "### Definition\n",
    "\n",
    "$RMSE = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 } = \\sqrt{MSE}$\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- RMSE is easier to interpret than MSE because it is in the **original unit** of the target variable.\n",
    "- It gives a direct sense of **how far off predictions are**, on average.\n",
    "- Like MSE, it is also sensitive to outliers due to the squaring.\n",
    "\n",
    "### Example\n",
    "\n",
    "In this case, the RMSE is approximately **298â€¯N**.  \n",
    "Given that the mean of the target variable (PullTest) is **2953â€¯N**, this corresponds to a **relative prediction error of about 10.1â€¯%**.\n",
    "\n",
    "This means that, on average, the model's predictions deviate from the true pull test values by approximately 298â€¯N.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a018d2a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06baded6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m X_train_new \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaterial\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComments\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      4\u001b[0m X_dev_new \u001b[38;5;241m=\u001b[39m X_dev\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaterial\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComments\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      7\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train_new, y_train)\n\u001b[0;32m      8\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_dev_new)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "X_train_new = X_train.drop(columns=[\"Material\", \"Category\", \"Comments\"])\n",
    "X_dev_new = X_dev.drop(columns=[\"Material\", \"Category\", \"Comments\"])\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_new, y_train)\n",
    "    preds = model.predict(X_dev_new)\n",
    "    \n",
    "    mse = mean_squared_error(y_dev, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_dev, preds)\n",
    "    \n",
    "    results[name] = {\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"RÂ²\": r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21b57703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     MSE    RMSE    RÂ²\n",
      "TabPFN          71549.75  267.49  0.69\n",
      "Decision Tree   81260.90  285.06  0.64\n",
      "Random Forest   73589.86  271.27  0.68\n",
      "XGBoost        113405.48  336.76  0.50\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(2)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2605ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_data = {}  \n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_new, y_train)\n",
    "    preds = model.predict(X_dev_new)\n",
    "    \n",
    "    mse = mean_squared_error(y_dev, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_dev, preds)\n",
    "    \n",
    "    results[name] = {\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"RÂ²\": r2\n",
    "    }\n",
    "    \n",
    "    abs_errors = np.abs(preds - y_dev)\n",
    "    sorted_errors = np.sort(abs_errors)\n",
    "    cdf = np.arange(1, len(sorted_errors)+1) / len(sorted_errors)\n",
    "    cdf_data[name] = (sorted_errors, cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5ae27f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for name, (errors, cdf) in cdf_data.items():\n",
    "    plt.plot(errors, cdf, label=name)\n",
    "\n",
    "plt.xlabel(\"Absolute Error |Å· - y| [N]\")\n",
    "plt.ylabel(\"Cumulative Probability\")\n",
    "plt.title(\"CDF of Absolute Prediction Errors per Model\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
